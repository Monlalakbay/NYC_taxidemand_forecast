{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 00_analysis.ipynb ‚Äî Model Engineering Analysis & Insights",
   "id": "17f26c20309710be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import IFrame, display, HTML"
   ],
   "id": "f8ea5ee5dc2465d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## I. Setup paths",
   "id": "2ebd91d6ffcf217e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Detect project root (go 1‚Äì2 levels up if inside /notebooks)\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if not os.path.exists(os.path.join(BASE_DIR, \"data\", \"evaluation\")):\n",
    "    BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "\n",
    "print(f\"üìÇ Project root resolved to: {BASE_DIR}\")\n",
    "EVAL_DIR = os.path.join(BASE_DIR, \"data\", \"evaluation\")\n",
    "RUNS_DIR = os.path.join(BASE_DIR, \"data\", \"runs\")\n",
    "LOG_PATH = os.path.join(BASE_DIR, \"data\", \"pipeline_log.csv\")\n",
    "\n",
    "\n",
    "print(f\"üìÇ Project root: {BASE_DIR}\")"
   ],
   "id": "41c82029f2bec4c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## II. Load latest evaluation summary",
   "id": "c0bb2a828d314bc8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "eval_files = sorted(\n",
    "    [f for f in os.listdir(EVAL_DIR) if f.startswith(\"all_models_eval_test_\")],\n",
    "    key=lambda x: os.path.getmtime(os.path.join(EVAL_DIR, x))\n",
    ")\n",
    "latest_eval = os.path.join(EVAL_DIR, eval_files[-1]) if eval_files else None\n",
    "\n",
    "if latest_eval:\n",
    "    df_eval = pd.read_csv(latest_eval)\n",
    "    print(f\"‚úÖ Loaded evaluation summary: {os.path.basename(latest_eval)} ({len(df_eval)} districts)\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"‚ùå No evaluation summary found in data/evaluation.\")\n",
    "\n",
    "display(df_eval.head(10))\n"
   ],
   "id": "942ee5f5f2c2000b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "District-level differences highlight local variability. Manhattan zones show higher error margins due to volatility in pickup volume, while Brooklyn performs more steadily.\n",
    "\n",
    "The evaluation table compares RMSE and MAE across four models (Random Forest, LightGBM, ConvLSTM, and Hybrid). Hybrid models consistently outperform single learners, confirming that blending tree-based and neural architectures improves predictive robustness."
   ],
   "id": "642e7a75c6376d2f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## III. Performance overview",
   "id": "75d5dbdf426b1859"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(df_eval, y=\"district\", x=\"mean_rmse\", color=\"steelblue\")\n",
    "plt.title(\"Average RMSE across all models by district\")\n",
    "plt.xlabel(\"RMSE\")\n",
    "plt.ylabel(\"\")\n",
    "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare model performances\n",
    "models = [\"rmse_rf\", \"rmse_lgbm\", \"rmse_conv\", \"rmse_hybrid\"]\n",
    "df_melt = df_eval.melt(id_vars=[\"district\"], value_vars=models, var_name=\"Model\", value_name=\"RMSE\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(df_melt, x=\"Model\", y=\"RMSE\", palette=\"Set2\")\n",
    "plt.title(\"RMSE Distribution across Models\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b101eb437f46ea39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Brooklyn CD 01 and CD 02 exhibit the lowest RMSE, showing strong model fit.\n",
    "\n",
    "Districts with higher night-time and event-driven demand (e.g., Manhattan CD 05) naturally produce higher RMSE due to irregular peaks that are harder to model."
   ],
   "id": "c87e12153657464a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## IV. Time-series comparison (actual vs. predicted)",
   "id": "b0295e9d4fab94e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# Path to the latest tree-based prediction folder\n",
    "runs_dir = os.path.join(BASE_DIR, \"data\", \"runs\")\n",
    "tree_runs = sorted([d for d in os.listdir(runs_dir) if d.startswith(\"tree_preds_\")])\n",
    "latest_tree_run = os.path.join(runs_dir, tree_runs[-1], \"predictions\")\n",
    "\n",
    "print(f\"üìÅ Loading predictions from: {latest_tree_run}\")\n",
    "\n",
    "# Select 2‚Äì3 example districts for visualization\n",
    "example_districts = [\"Manhattan CD 01\", \"Manhattan CD 05\", \"Brooklyn CD 01\", \"Manhattan CD 02\", \"Manhattan CD 04\", \"Manhattan CD 06\", \"Manhattan CD 08\", \"Manhattan CD 03\", \"Manhattan CD 07\"]\n",
    "\n",
    "for district in example_districts:\n",
    "    slug = district.replace(\" \", \"_\")\n",
    "    pred_path = os.path.join(latest_tree_run, f\"ensemble_preds_{slug}.csv\")\n",
    "    if not os.path.exists(pred_path):\n",
    "        print(f\"‚ö†Ô∏è Skipping {district} (no prediction file found)\")\n",
    "        continue\n",
    "\n",
    "    df_pred = pd.read_csv(pred_path, parse_dates=[\"pickup_datetime\"])\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df_pred[\"pickup_datetime\"], df_pred[\"y_true\"], label=\"Actual Demand\", color=\"black\", linewidth=1.5)\n",
    "    plt.plot(df_pred[\"pickup_datetime\"], df_pred[\"pred_rf\"], label=\"RF Prediction\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.plot(df_pred[\"pickup_datetime\"], df_pred[\"pred_lgbm\"], label=\"LGBM Prediction\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.plot(df_pred[\"pickup_datetime\"], df_pred[\"pred_ensemble\"], label=\"Hybrid (RF+LGBM)\", color=\"orange\", linewidth=2)\n",
    "\n",
    "    plt.title(f\"Actual vs Predicted Taxi Demand ‚Äî {district}\")\n",
    "    plt.xlabel(\"Datetime\")\n",
    "    plt.ylabel(\"Pickups per Hour\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "4fa1c79b796bb623",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The models effectively capture hourly periodicity and weekly repetition, crucial for optimizing taxi distribution.\n",
    "\n",
    "Slight deviations appear during abrupt surges, but the ensemble maintains consistency and avoids overfitting noise. For operational use, this means reliable short-term forecasts, but potential gains if external data (e.g., profile of passengers, events or weather) were added."
   ],
   "id": "128bf1f4aee96d54"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## V. Identify best models per district",
   "id": "320f4ec7fa4daf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Identify best models per district\n",
    "eval_dir = os.path.join(BASE_DIR, \"data\", \"evaluation\")\n",
    "summary_files = sorted([f for f in os.listdir(eval_dir) if f.startswith(\"all_models_eval_test\")])\n",
    "\n",
    "if not summary_files:\n",
    "    raise FileNotFoundError(\"‚ùå No evaluation summary found\")\n",
    "\n",
    "eval_path = os.path.join(eval_dir, summary_files[-1])\n",
    "df_eval = pd.read_csv(eval_path)\n",
    "\n",
    "rmse_cols = [c for c in df_eval.columns if c.startswith(\"rmse_\")]\n",
    "df_eval[\"best_model\"] = df_eval[rmse_cols].idxmin(axis=1)\n",
    "\n",
    "best_counts = df_eval[\"best_model\"].value_counts()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(\n",
    "    x=best_counts.index.str.replace(\"rmse_\", \"\").str.upper(),\n",
    "    y=best_counts.values,\n",
    "    palette=\"viridis\"\n",
    ")\n",
    "plt.title(\"Best Model Type by District\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Model Type\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "f221ccf700cb0db6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## VI. Pipeline run log summary",
   "id": "50fc71e0e107412b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if os.path.exists(LOG_PATH):\n",
    "    try:\n",
    "        # Try normal fast read first\n",
    "        log_df = pd.read_csv(LOG_PATH)\n",
    "    except pd.errors.ParserError:\n",
    "        # Fallback for inconsistent lines (old vs. new schema)\n",
    "        log_df = pd.read_csv(LOG_PATH, on_bad_lines=\"skip\", engine=\"python\")\n",
    "        print(\"‚ö†Ô∏è Some malformed log lines were skipped due to inconsistent columns.\")\n",
    "\n",
    "    # --- Standardize columns ---\n",
    "    expected_cols = [\"timestamp\", \"step\", \"duration_min\", \"status\", \"details\"]\n",
    "    for col in expected_cols:\n",
    "        if col not in log_df.columns:\n",
    "            log_df[col] = np.nan\n",
    "\n",
    "    # --- Clean up ---\n",
    "    log_df = log_df[expected_cols].drop_duplicates().reset_index(drop=True)\n",
    "    log_df[\"duration_min\"] = pd.to_numeric(log_df[\"duration_min\"], errors=\"coerce\")\n",
    "    log_df = log_df.dropna(subset=[\"step\"])\n",
    "\n",
    "    display(HTML(\"<h4>üìã Recent Pipeline Runs</h4>\"))\n",
    "    display(log_df.tail(10))\n",
    "\n",
    "    # --- Plot runtime chart ---\n",
    "    plt.figure(figsize=(9, 4))\n",
    "    sns.barplot(log_df, x=\"step\", y=\"duration_min\", color=\"#FF6F61\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.title(\"Pipeline Step Duration (minutes)\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"Duration (min)\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- Step success overview ---\n",
    "    success_rate = (log_df[\"status\"].str.contains(\"success\", case=False, na=False).mean()) * 100\n",
    "    print(f\"‚úÖ Pipeline success rate: {success_rate:.1f}%\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No pipeline log found ‚Äî please run the pipeline first.\")\n"
   ],
   "id": "7fa3c0c07b4a722c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Training duration per pipeline run remains efficient (<1 minute for top districts), suitable for continuous daily or hourly updates.",
   "id": "a7dc6bf8ef551d5e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## VII. Interactive map visualization",
   "id": "bc941c2d7cc58ef3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Shows a next hour demand forecast and which model is used per district.",
   "id": "8477b1257c2767e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import IFrame, display\n",
    "\n",
    "maps_dir = os.path.join(EVAL_DIR, \"maps\")\n",
    "if os.path.exists(maps_dir):\n",
    "    map_files = sorted(\n",
    "        [f for f in os.listdir(maps_dir) if f.endswith(\".html\")],\n",
    "        key=lambda x: os.path.getmtime(os.path.join(maps_dir, x))\n",
    "    )\n",
    "    latest_map = os.path.join(maps_dir, map_files[-1]) if map_files else None\n",
    "else:\n",
    "    latest_map = None\n",
    "\n",
    "if latest_map:\n",
    "    print(f\"üó∫Ô∏è Displaying saved map: {os.path.basename(latest_map)}\")\n",
    "    # ‚úÖ Embed the HTML map inside the notebook\n",
    "    display(IFrame(src=latest_map, width=\"100%\", height=\"600\"))\n",
    "\n",
    "    print(f\"üìÅ Full path: {latest_map}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No Folium map found in evaluation/maps.\")\n"
   ],
   "id": "162068d5d32baeca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## VIII. Business Insights",
   "id": "4f3af5562a22e5c9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The map provides a real-time, spatial view of predicted next-hour demand. Circle size reflects predicted pickup intensity; color represents the model type with the best performance per district. This forecast enables better fleet balancing and dispatch optimization.",
   "id": "e8f82927bdec9401"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Results show that hybrid (RF + LGBM + ConvLSTM blend) model is performing best in most districts. They mostly dominate in central Manhattan, where temporal patterns are complex and benefit from the deep model‚Äôs structure awareness.\n",
    "\n",
    "RF win in Manhattan CD 04, 07 and CD 08, which are both business-heavy districts with more predictable demand cycles and less noise.\n",
    "\n",
    "LGBM performs the strongest in Brooklyn CD 02 (RMSE ‚âà 10.57), probably due to consisitent residential demand patterns.\n",
    "\n",
    "The combination of ConvLSTM alone perfroms worse in comparison to other models where demand is irregular or sparse. The reason could be that the deep models overfit or underfit due to data scarcity. Manhattan CD 05 could benefit from a different model due to its higly volatile Midtown traffic."
   ],
   "id": "ef0b0300aee143b6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
